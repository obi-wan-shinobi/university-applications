\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{newtxmath,newtxtext}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\Hrule}{\rule{\linewidth}{0.3mm}}

\makeatletter% since there's an at-sign (@) in the command name
\renewcommand{\@maketitle}{%
  \parindent=0pt% don't indent paragraphs in the title block
  \centering
  {\Large \bfseries\textsc{\@title}}
  \HRule\par%
  \textit{\@author \hfill \@date}
  \par
}
\makeatother% resets the meaning of the at-sign (@)

\title{Statement of Academic Purpose}
\author{Shreyas Kalvankar}
\date{M.S. Applicant}

\begin{document}
  \maketitle% prints the title block
  \thispagestyle{empty}
My research interests lie in uncovering the mathematics that drives Machine
Learning and deep learning and their theoretical nature. What are the
theoretical foundations explaining the success of deep networks? Are there
inherent limits to their expressiveness? What are the potential applications of
learned representations in various domains, such as computer vision, natural
language processing, and speech recognition? How do we address the challenges of
interpretability and explainability in these learned representations? I aim to
explore these problems to develop an understanding of the theoretical limits of
Machine Learning. I am particularly interested in understanding and applying
these algorithms across engineering and natural sciences to build intelligent
systems and conduct research in physics and mathematics to solve problems such
as approximating numerical computations using neural networks, astronomical
simulations, assisted theorem proving, etc. My unwavering passion for
engineering and research is evident in my academic achievements during my
undergraduate years, reflected in my transcripts and my active involvement in
extracurricular activities. My journey has underscored the importance of further
specialization and enrichment, which I believe a master's program can provide,
laying the foundation for a future Ph.D. pursuit. In this regard, I am convinced
that Princeton University is the ideal place to nurture my potential.

During my bachelor's I was extremely fascinated by astrophysics and its
intersection with computer science. In my junior year, I led a team of three and
delved into the research on neural network applications in galaxy morphology
classification. Identifying galaxy morphologies has important implications in
many astronomical tasks, e.g., studying galaxy evolution, probing dark matter
distribution, etc. The recent data influx
in astronomy necessitates a robust and automated system for processing large
amounts of images. We aimed to set up a 7-class classification system that
classified galaxy images using CNNs, which can surpass existing benchmarks. I
was responsible for establishing a robust training pipeline and optimizing
various neural network architectures from the ground up. Our collective efforts
outperformed the second-best submission on the Kaggle Public Leaderboard. I
gained a profound understanding of the intricacies of applying deep learning to
various tasks and explored aspects such as hyperparameter tuning, debugging,
troubleshooting, and custom model design—each underscored by a need for a
profound grasp of the underlying theory. Consequently, I eagerly anticipate the
advanced topics in coursework such as \textit{'Fundamentals of Deep Learning'} by 
Dr. Sanjeev Arora, offering a more in-depth exploration of the core principles
of deep learning and rigorous mathematics compared to my prior senior-year
coursework.

The Galaxy Morphology Classification project proved to be a stepping stone in
connecting astrophysics to computer science. Soon after that project, I began
contributing to \textit{EinsteinPy}, an open-source Python package designed to address
issues in General Relativity and gravitational physics. My work specifically
involved incorporating various symbolic computations, such as the
Reissner–Nordström metric and calculations for the event horizon and ergosphere
of a Kerr-Newmann black hole. While symbolic computations are valuable in
controlled environments, real-world problems often necessitate approximate
rather than exact solutions. This led me to investigate the processes used for
various physical simulations where numerical methods are widely popular. The
potential for deep learning in simulating complex system behaviors is vast,
e.g., in surrogate modeling where we can use deep learning to approximate
behaviors in complex systems allowing for faster evaluations when original
simulation using numerical methods is computationally expensive. I am interested
in leveraging AI and Machine Learning for this task in the long term. Dr.
Ryan Adam's interests in computational statistics align extremely well with
mine. Moreover, his \textit{'Mathematics for Numerical Computing and Machine
Learning'} course seems extremely fascinating and promises a comprehensive exploration of
various mathematical concepts that extend beyond my previous academic
coursework. 

For my bachelor’s thesis, I worked on utilizing Conditional GANs for
astronomical image colorization. Space archives are filled with large amounts of
low-quality, greyscale images, many of which go unnoticed. I was interested in
utilizing generative models for creating aesthetically pleasing representations
of celestial scenes. Generative models are attractive because they enable us to
better understand, create, and work with data, having many practical and
theoretical implications. In my work, I focused on tasks like image-to-image
translation and style transfer, where I realized the need for distributional
robustness in my application to maintain quality in my output images, even in
varying conditions. GANs often deal with high-dimensional data and are used for
various conditional image generation tasks. In my ongoing academic journey, I’m
equally interested in gaining a theoretical understanding of how various neural
network models generalize, especially in complex, high-dimensional spaces when
provided with different conditions or inputs. Undergraduate studies seldom
comprehensively cover advanced machine learning theory. In this regard, I see
the coursework in \textit{'Theoretical Machine Learning'} as an exhilarating opportunity
to immerse myself in these concepts more formally than ever. It promises a more
profound understanding and a pathway to engaging with these fundamental theories
at a higher level.

For the past two years, I have been working as an ML consultant at Relfor Labs,
an AI startup. My professional experience in Machine Learning has further
motivated me to pursue graduate studies to kick-start a research career. The
scientific landscape has been consistently evolving, but many longstanding
problems have eluded complete solutions for many years. Looking into the future,
I wish to make a difference in this significant era. My determination to pursue
a research career is unwavering, and I aspire to work in an academic setting and
eventually pursue a Ph.D. The vibrant community of students and researchers at
Princeton is the perfect place for me to nurture myself and further my
commitment to help expedite this scientific advancement. Thank you for
considering me as a prospective student at your university.


\end{document}
